{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. What is the definition of a target function? In the sense of a real-life example, express the target function. How is a target function's fitness assessed?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A target function maps data to its target value.\n",
    "If we have picture of a digit, the function then receives that picture as the input and spit the digit value as the output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. What are predictive models, and how do they work? What are descriptive types, and how do you use them? Examples of both types of models should be provided. Distinguish between these two forms of models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "The predictive modeling is a statistical technique using machine learning  to predict and forecast likely future \n",
    "outcomes with the aid of historical and existing data. It works by analyzing current and historical data and projecting what it \n",
    "learns on a model generated to forecast likely outcomes.Predictive model can be used to predict  as income, laboratory values, \n",
    "test scores, or counts of items. \n",
    "\n",
    "A descriptive model is used for tasks that would benefit from the insight gained from summarizing data in new and interesting\n",
    "ways.the process of training a descriptive model is called unsupervised learning.he descriptive modeling task called pattern \n",
    "discovery is used to identify useful associations within data. Pattern discovery is often used for market basket analysis on \n",
    "retailers' transactional purchase data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Describe the method of assessing a classification model's efficiency in detail. Describe the various measurement parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.\n",
    "i. In the sense of machine learning models, what is underfitting? What is the most common\n",
    "reason for underfitting?\n",
    "ii. What does it mean to overfit? When is it going to happen?\n",
    "iii. In the sense of model fitting, explain the bias-variance trade-off."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Underfitting refers to a model that can neither model the training data nor generalize to new data. An underfit machine learning\n",
    "model is not a suitable model and will be obvious as it will have poor performance on the training data.\n",
    "When a model has not learned the patterns in the training data well and is unable to generalize well on the new data, it is \n",
    "known as underfitting. An underfit model has poor performance on the training data and will result in unreliable predictions. \n",
    "Underfitting occurs due to high bias and low variance.\n",
    "\n",
    "Overfitting is a modeling error in statistics that occurs when a function is too closely aligned to a limited set of data points\n",
    ". As a result, the model is useful in reference only to its initial data set, and not to any other data sets.\n",
    "\n",
    "\n",
    "In statistics and machine learning, the bias–variance tradeoff is the property of a model that the variance of the parameter \n",
    "estimated across samples can be reduced by increasing the bias in the estimated parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Is it possible to boost the efficiency of a learning model? If so, please clarify how."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yes,it Is possible to boost the efficiency of a learning model.\n",
    "\n",
    "Add more data\n",
    "Treat missing and Outlier values\n",
    "Feature Engineering\n",
    "Feature Selection   \n",
    "Multiple algorithms\n",
    "Algorithm Tuning\n",
    "Ensemble methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. How would you rate an unsupervised learning model's success? What are the most common success indicators for an unsupervised learning model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Using:\n",
    "    Silhouette coefficient\n",
    "    Calisnki-Harabasz coefficient\n",
    "    Dunn index\n",
    "    Xie-Beni score\n",
    "    Hartigan index\n",
    "    \n",
    "The two most popular metrics evaluation metrics for clustering algorithms are the Silhouette coefficient and Dunn’s Index    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Is it possible to use a classification model for numerical data or a regression model for categorical data with a classification model? Explain your answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "No it is not possible to use a classification model for numerical data or a regression model for categorical data with a \n",
    "classification model because A classification model tries to draw some conclusion from the input values given for training. It \n",
    "will predict the class labels/categories for the new data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Describe the predictive modeling method for numerical values. What distinguishes it from categorical predictive modeling?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " predictive modeling is a statistical technique using machine learning and data mining to predict and forecast likely future \n",
    " outcomes with the aid of historical and existing data. It works by analyzing current and historical data and projecting \n",
    " what it learns on a model generated to forecast likely outcomes.mathod for neumerical values:\n",
    "    Time series model\n",
    "    Forecast model:\n",
    "    Outliers model\n",
    "\n",
    "categorical predictive modeling:    \n",
    "Convert to number: As discussed above, some ML libraries do not take categorical variables as input. Thus, we convert them\n",
    "into numerical variables. Below are the methods to convert a categorical (string) input to numerical nature:\n",
    "Label Encoder: It is used to transform non-numerical labels to numerical labels (or nominal categorical variables). Numerical \n",
    "labels are always between 0 and n_classes-1. \n",
    "Convert numeric bins to number.\n",
    "Combine Levels\n",
    "Combine levels: To avoid redundant levels in a categorical variable and to deal with rare levels, we can simply combine the \n",
    "    different levels. There are various methods of combining levels. Here are commonly used ones:\n",
    "Using Business Logic.\n",
    "Dummy Coding: Dummy coding is a commonly used method for converting a categorical input variable into continuous variable.\n",
    "Using frequency or response rate    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. The following data were collected when using a classification model to predict the malignancy of a group of patient's tumors:\n",
    "i. Accurate estimates – 15 cancerous, 75 benign\n",
    "ii. Wrong predictions – 3 cancerous, 7 benign\n",
    "Determine the model's error rate, Kappa value, sensitivity, precision, and F-measure. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Precision=63%\n",
    "error rate=11.11%\n",
    "f-measure=70.48%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10. Make quick notes on:\n",
    "1. The process of holding out\n",
    "2. Cross-validation by tenfold\n",
    "3. Adjusting the parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "2.Cross-validation is a technique to evaluate predictive models by partitioning the original sample into a training set to train \n",
    "the model, and a test set to evaluate it.The dataset was divided into ten parts, and nine of them were taken as training data in\n",
    "turn, and one was used as test data for testing. The average value E of the ten-groups test results is calculated as an estimate\n",
    "of the model accuracy and is used as a performance indicator for the current K-fold cross-validation model.\n",
    "\n",
    "3.Hyperparameters are used by the learning algorithm when it is learning but they are not part of the resulting model. At the \n",
    "end of the learning process, we have the trained model parameters which effectively is what we refer to as the model. The \n",
    "hyperparameters that were used during training are not part of this model. We cannot for instance know what hyperparameter \n",
    "values were used to train a model from the model itself, we only know the model parameters that were learned."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 11. Define the following terms:\n",
    "1. Purity vs. Silhouette width\n",
    "2. Boosting vs. Bagging\n",
    "3. The eager learner vs. the lazy learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "We sum the number of correct class labels in each cluster and divide it by the total number of data points. In general, purity \n",
    "increases as the number of clusters increases. For instance, if we have a model that groups each observation in a separate \n",
    "cluster, the purity becomes one.\n",
    "The  Silhouette Width  is a popular cluster validation index to estimate the number of clusters. The question \n",
    "whether it also is suitable as a general objective function to be optimized for finding a clustering is addressed.\n",
    "\n",
    "Bagging is a technique for reducing prediction variance by producing additional data for training from a dataset by combining \n",
    "repetitions with combinations to create multi-sets of the original data. Boosting is an iterative strategy for adjusting an \n",
    "observation's weight based on the previous classification.\n",
    "\n",
    "Lazy learner:\n",
    "\n",
    "1.Just store Data set without learning from it\n",
    "\n",
    "2.Start classifying data when it receive Test data\n",
    "\n",
    "3.So it takes less time learning and more time classifying data\n",
    "\n",
    "Eager learner:\n",
    "\n",
    "1.When it receive data set it starts classifying (learning)\n",
    "\n",
    "2.Then it does not wait for test data to learn\n",
    "\n",
    "3.So it takes long time learning and less time classifying data\n",
    "\n",
    "A lazy learner delays abstracting from the data until it is asked to make a prediction while an eager learner abstracts away \n",
    "from the data during training and uses this abstraction to make predictions rather than directly compare queries with instances \n",
    "in the dataset."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
