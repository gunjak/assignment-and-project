{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In the sense of machine learning, what is a model? What is the best way to train a model? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A machine learning model is a file that has been trained to recognize certain types of patterns.\n",
    "\n",
    "Step 1: Begin with existing data. Machine learning requires us to have existing data—not the data our application will use when \n",
    "       we run it, but data to learn from.\n",
    "Step 2: Analyze data to identify patterns. \n",
    "Step 3: Make predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In the sense of machine learning, explain the &quot;No Free Lunch&quot; theorem. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "The “no free lunch” (NFL) theorem for supervised machine learning is a theorem that essentially implies that no single machine \n",
    "learning algorithm is universally the best-performing algorithm for all problems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Describe the K-fold cross-validation mechanism in detail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Cross-validation is a resampling procedure used to evaluate machine learning models on a limited data sample. The procedure has\n",
    "a single parameter called k that refers to the number of groups that a given data sample is to be split into."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Describe the bootstrap sampling method. What is the aim of it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "The bootstrap method is a statistical technique for estimating quantities about a population by averaging estimates from multiple\n",
    "small data samples.\n",
    "\n",
    "The idea behind bootstrap is to use the data of a sample study at hand as a surrogate population,for the purpose ofapproximating\n",
    "the sampling distribution of a statistic; that is, to resample from the sample data at hand and create a large number of phantom \n",
    "samples known as bootstrap samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is the significance of calculating the Kappa value for a classification model? Demonstrate how to measure the Kappa value of a classification model using a sample collection of results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "It basically tells you how much better your classifier is performing over the performance of a classifier that simply guesses \n",
    "at random according to the frequency of each class. Cohen's kappa is always less than or equal to 1. Values of 0 or less, \n",
    "indicate that the classifier is useless."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Describe the model ensemble method. In machine learning, what part does it play?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " Ensemble methods use multiple learning algorithms to obtain better predictive performance than could be obtained from any of \n",
    "the constituent learning algorithms alone.Ensemble methods are techniques that create multiple models and then combine them to\n",
    "produce improved results. Ensemble methods usually produces more accurate solutions than a single model would. \n",
    "\n",
    "Ensemble learning is a general meta approach to machine learning that seeks better predictive performance by combining the \n",
    "predictions from multiple models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is a descriptive model's main purpose? Give examples of real-world problems that descriptive models were used to solve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Descriptive models  help an organization to know what has happened in the past, it would give you the past analytics \n",
    "using the data that are stored.\n",
    "\n",
    "Customer segmentation: Partitions a customer base into groups with various impacts on marketing and service.\n",
    "Value-based segmentation: Identifies and quantifies the value of a customer to the organization.\n",
    "Behavior-based segmentation: Analyzes customer product usage and purchasing patterns.\n",
    "Needs-based segmentation: Identifies ways to capitalize on motives that drive customer behavior."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Describe how to evaluate a linear regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "There are 3 main metrics for model evaluation in regression:\n",
    "1. R Square/Adjusted R Square:\n",
    "    R Square measures how much variability in dependent variable can be explained by the model.R Square is a good measure to \n",
    "    determine how well the model fits the dependent variables\n",
    "2. Mean Square Error(MSE)/Root Mean Square Error(RMSE):\n",
    "    Mean Square Error is an absolute  measure of the goodness for the fit.t gives you an absolute number on how much your\n",
    "    predicted results deviate from the actual number.\n",
    "3. Mean Absolute Error(MAE):\n",
    "    MSE gives larger penalization to big prediction error by square it while MAE treats all errors the same."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distinguish :\n",
    "\n",
    "1. Descriptive vs. predictive models\n",
    "\n",
    "2. Underfitting vs. overfitting the model\n",
    "\n",
    "3. Bootstrapping vs. cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Descriptive vs. predictive:\n",
    "    \n",
    "Predictive models help an organization to know what might happen next, it predicts future based on present data \n",
    "available.\n",
    "Descriptive models  help an organization to know what has happened in the past, it would give you the past analytics \n",
    "using the data that are stored. \n",
    "\n",
    "Underfitting vs. overfitting the model:\n",
    "    \n",
    "A  machine learning algorithm is said to have underfitting when it cannot capture the underlying trend of the data.Underfitting \n",
    "destroys the accuracy of our machine learning model .\n",
    "A statistical model is said to be overfitted when we train it with a lot of data . When a model gets trained with so much data,\n",
    "it starts learning from the noise and inaccurate data entries in our data set. Then the model does not categorize the data \n",
    "correctly, because of too many details and noise. The causes of overfitting are the non-parametric and non-linear methods \n",
    "because these types of machine learning algorithms have more freedom in building the model based on the dataset and therefore\n",
    "they can really build unrealistic models.\n",
    "\n",
    "Bootstrapping vs. cross-validation\n",
    "Cross validation is a method to measure the performance of one single model on different sets of data.\n",
    "Bootstrapping method uses the original dataset to create multiple datasets after resampling with replacement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make quick notes on:\n",
    "\n",
    "1. LOOCV.\n",
    "\n",
    "2. F-measurement\n",
    "\n",
    "3. The width of the silhouette\n",
    "\n",
    "4. Receiver operating characteristic curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOOCV:\n",
    "    The Leave-One-Out Cross-Validation, or LOOCV, procedure is used to estimate the performance of machine learning algorithms \n",
    "    when they are used to make predictions on data not used to train the model.\n",
    "    Split a dataset into a training set and a testing set, using all but one observation as part of the training set\n",
    "    The algorithm of LOOCV technique:\n",
    "\n",
    "    Choose one sample from the dataset which will be the test set\n",
    "    The remaining n – 1 samples will be the training set\n",
    "    Train the model on the training set. On each iteration, a new model must be trained\n",
    "    Validate on the test set\n",
    "    Save the result of the validation\n",
    "    Repeat steps 1 – 5 n times as for n samples we have n different training and test sets\n",
    "    To get the final score average the results that you got on step 5.\n",
    "    \n",
    "F-measurement:\n",
    "    The F-measure is calculated as the harmonic mean of precision and recall, giving each the same weighting. It allows a model\n",
    "    to be evaluated taking both the precision and recall into account using a single score, which is helpful when describing the\n",
    "    performance of the model and in comparing models.\n",
    "    \n",
    "The width of the silhouette:   \n",
    "    The Average Silhouette Width (ASW) of a clustering is the average distance of to points in the cluster to which \n",
    "    it was assigned, and is the average distance of to the points in the nearest cluster to which it was not assigned.\n",
    "    \n",
    "Receiver operating characteristic curve    \n",
    "    The Receiver Operator Characteristic (ROC) curve is an evaluation metric for binary classification problems. It is a \n",
    "    probability curve that plots the TPR against FPR at various threshold values and essentially separates the 'signal' from \n",
    "    the 'noise'."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
