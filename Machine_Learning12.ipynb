{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. What is prior probability? Give an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A priori probability refers to the likelihood of an event occurring when there is a finite amount of outcomes and each is \n",
    "equally likely to occur. The outcomes in a priori probability are not influenced by the prior outcome.\n",
    "in the mortgage case, P(Y) is the default rate on a home mortgage, which is 2%. P(Y|X) is called the conditional probability, \n",
    "which provides the probability of an outcome given the evidence, that is, when the value of X is known."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. What is posterior probability? Give an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Posterior probability is a revised probability that takes into account new available information. For example, let there be two \n",
    "urns, urn A having 5 black balls and 10 red balls and urn B having 10 black balls and 5 red balls. Now if an urn is selected at \n",
    "random, the probability that urn A is chosen is 0.5.This is the a priori probability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. What is likelihood probability? Give an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Likelihood refers to how well a sample provides support for particular values of a parameter in a model.\n",
    "we flip the coin 100 times and it only lands on heads 17 times. We would say that the likelihood that the coin is fair is quite\n",
    "low. If the coin was actually fair, we would expect it to land on heads much more often."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. What is Naïve Bayes classifier? Why is it named so? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A naive Bayes classifier assumes that the presence  of a particular feature of a class is unrelated to the presence  of any \n",
    "other feature, given the class variable. Basically, it's \"naive\" because it makes assumptions that may or may not turn out to be\n",
    "correct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. What is optimal Bayes classifier?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "The Bayes Optimal Classifier is a probabilistic model that makes the most probable prediction for a new example. It is described\n",
    "using the Bayes Theorem that provides a principled way for calculating a conditional probability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Write any two features of Bayesian learning methods. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Bayesian methods can accommodate hypotheses that make probabilistic predictions.\n",
    "\n",
    "New instances can be classified by combining the predictions of multiple hypotheses,weighted by their probabilities.\n",
    "\n",
    "Prior knowledge can be combined with observed data to determine the final\n",
    "probability of a hypothesis. In Bayesian learning, prior knowledge is provided by\n",
    "asserting\n",
    "– a prior probability for each candidate hypothesis, and\n",
    "– a probability distribution over observed data for each possible hypothesis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Define the concept of consistent learners."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Consistent Learners. • A learner L using a hypothesis H and training data D is said to be a consistent learner if it always \n",
    "outputs a hypothesis with zero error on D whenever H contains such a hypothesis. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Write any two strengths of Bayes classifier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "This algorithm works quickly and can save a lot of time. \n",
    "\n",
    "Naive Bayes is suitable for solving multi-class prediction problems.\n",
    "\n",
    "If its assumption of the independence of features holds true, it can perform better than other models and requires much less \n",
    "training data. \n",
    "\n",
    "Naive Bayes is better suited for categorical input variables than numerical variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. Write any two weaknesses of Bayes classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Naive Bayes assumes that all predictors (or features) are independent, rarely happening in real life. This limits the \n",
    "applicability of this algorithm in real-world use cases.\n",
    "\n",
    "This algorithm faces the ‘zero-frequency problem’ where it assigns zero probability to a categorical variable whose category in\n",
    "the test data set wasn’t available in the training dataset. It would be best if you used a smoothing technique to overcome this\n",
    "issue.\n",
    "\n",
    "Its estimations can be wrong in some cases, so you shouldn’t take its probability outputs very seriously. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10. Explain how Naïve Bayes classifier is used for\n",
    "\n",
    "1. Text classification\n",
    "\n",
    "2. Spam filtering\n",
    "\n",
    "3. Market sentiment analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1.\n",
    "2.Naive Bayes classifiers work by correlating the use of tokens , with spam and non-spam e-mails and then using Bayes' theorem \n",
    "to calculate a probability that an email is or is not spam."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
